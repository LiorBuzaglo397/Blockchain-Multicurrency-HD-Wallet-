{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiorBuzaglo397/Blockchain-Multicurrency-HD-Wallet-/blob/main/vision_project_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPkSHwjJoi93"
      },
      "source": [
        "## General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guj53sa0odeF",
        "outputId": "95e34615-98da-456b-afcd-9cac5144d2d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Final-Project'...\n",
            "remote: Enumerating objects: 124563, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 124563 (delta 40), reused 9 (delta 9), pack-reused 124513 (from 2)\u001b[K\n",
            "Receiving objects: 100% (124563/124563), 2.99 GiB | 17.26 MiB/s, done.\n",
            "Resolving deltas: 100% (3031/3031), done.\n",
            "Updating files: 100% (27605/27605), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NitzanEz/Final-Project.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pobfkusVoeWr",
        "outputId": "fb731d26-cab4-4a01-f5e7-5761b66c0524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2024.12.14)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->monai) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio timm\n",
        "!pip install transformers\n",
        "!pip install matplotlib  # For plotting\n",
        "!pip install monai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJt2I6Vg-9sK"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UeHOci7_BNC"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "72eazAn5_C4f"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# from monai.transforms import Compose, EnsureTyped, NormalizeIntensityd, ToTensorD\n",
        "# from monai.utils.type_conversion import convert_to_tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcrbHISq_DAH"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L1dbagK7MDse"
      },
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "image_size = 299\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),  # Resize the image to 299x299\n",
        "    transforms.ToTensor(),  # Converts PIL Image to Tensor.\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the images.\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Load training and validation datasets\n",
        "train_dataset = datasets.ImageFolder('/content/Final-Project/Data/train', transform=data_transform)\n",
        "val_dataset = datasets.ImageFolder('/content/Final-Project/Data/validation', transform=data_transform)\n",
        "test_dataset = datasets.ImageFolder('/content/Final-Project/Data/test', transform=data_transform)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of images in each dataset\n",
        "print(f\"Number of training images: {len(train_dataset)}\")\n",
        "print(f\"Number of validation images: {len(val_dataset)}\")\n",
        "print(f\"Number of test images: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "JfIjvMWi0qRX",
        "outputId": "0d2ce083-2381-46ee-ebf3-3b7cede76e89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 19503\n",
            "Number of validation images: 5437\n",
            "Number of test images: 2656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHDl-Xlz_Hb1"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWTihfBL_LQS"
      },
      "source": [
        "#### Configuration and Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gTFF1UpF_LXM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Training Parameters\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "learning_rate = 0.0005\n",
        "# weight_decay = 5e-4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "# Model setup\n",
        "model = timm.create_model('inception_v4', pretrained=True)\n",
        "num_features = model.last_linear.in_features  # Get the number of input features to the last layer\n",
        "\n",
        "\n",
        "hidden_size = 128\n",
        "model.last_linear = nn.Sequential(\n",
        "    nn.Linear(num_features, hidden_size),\n",
        "    nn.BatchNorm1d(hidden_size),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "nn.init.xavier_uniform_(model.last_linear[0].weight)\n",
        "nn.init.xavier_uniform_(model.last_linear[4].weight)\n",
        "nn.init.zeros_(model.last_linear[0].bias)\n",
        "nn.init.zeros_(model.last_linear[4].bias)\n",
        "model.to(device)\n",
        "\n",
        "# model.last_linear = nn.Sequential(\n",
        "#     nn.Linear(num_features, 256),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Dropout(0.5),\n",
        "#     nn.Linear(256, 2),\n",
        "# )\n",
        "# model.to(device)\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam( model.parameters(), lr=learning_rate)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.BCELoss()\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qGwHjdYJhiBL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxFQ_ZeC_SI7"
      },
      "source": [
        "#### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p_gbwF7w_z9-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def run_epoch(model,\n",
        "              data_loader,\n",
        "              device,\n",
        "              should_train: bool = False,\n",
        "              optimizer=None,\n",
        "              criterion=None,\n",
        "              scheduler=None,\n",
        "              verbose: bool = False,\n",
        "              best_model_path: str = None,\n",
        "              val_loader=None):\n",
        "    if should_train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_iterations = len(data_loader)\n",
        "\n",
        "    best_val_accuracy = 0.0  # Initialize best validation accuracy\n",
        "\n",
        "    with tqdm(total=total_iterations, desc=\"Progress\", bar_format=\"{l_bar}{bar} | {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}\") as pbar:\n",
        "        for i, (data, targets) in enumerate(data_loader):\n",
        "            data = data.to(device)\n",
        "            targets = targets.float().unsqueeze(1).to(device)\n",
        "\n",
        "            if should_train:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            if should_train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Step the scheduler (if provided) after the optimizer step\n",
        "                if scheduler is not None:\n",
        "                    scheduler.step()\n",
        "\n",
        "            custom_info = {}  # Custom parameters\n",
        "            if i != 0:\n",
        "                custom_info[\"loss\"] = running_loss / i\n",
        "                custom_info[\"accuracy\"] = 100 * correct / total\n",
        "\n",
        "            pbar.set_postfix(custom_info)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            correct += ((outputs >= 0.5) == targets).sum().item()  # Count correct predictions\n",
        "            total += targets.size(0)  # Total number of targets\n",
        "            pbar.update(1)\n",
        "\n",
        "    train_loss = running_loss / total_iterations\n",
        "    train_accuracy = 100 * correct / total\n",
        "\n",
        "    if val_loader is not None:  # If validation loader is provided, evaluate the model on validation set\n",
        "        val_accuracy = evaluate(model, val_loader, device, criterion)  # Assume evaluate function is defined\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            if best_model_path is not None:\n",
        "                torch.save(model.state_dict(), best_model_path)  # Save the model with the best validation accuracy\n",
        "                print(f\"Saved best model with validation accuracy: {best_val_accuracy:.2f}%\")\n",
        "\n",
        "    return train_loss, train_accuracy, best_val_accuracy\n",
        "\n",
        "\n",
        "def evaluate(model, val_loader, device, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, targets in val_loader:\n",
        "            data = data.to(device)\n",
        "            targets = targets.float().unsqueeze(1).to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            correct += ((outputs >= 0.5) == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    return val_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNfCetNWoeaH",
        "outputId": "7eb24cb8-2a7b-4bdc-c448-774fb1380150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████ | 610/610 [02:15<00:00] , loss=0.0575, accuracy=98.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best model with validation accuracy: 61.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████ | 170/170 [00:27<00:00] , loss=1.52, accuracy=61.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50]: Train Loss: 0.0575, Train Acc: 98.24%, Val Loss: 1.5202, Val Acc: 61.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████ | 610/610 [02:14<00:00] , loss=0.076, accuracy=97.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best model with validation accuracy: 66.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress:  46%|████▌      | 78/170 [00:12<00:14] , loss=1.42, accuracy=65.7"
          ]
        }
      ],
      "source": [
        "best_val_accuracy = 0.0\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Train the model for one epoch\n",
        "    train_loss, train_accuracy, best_val_accuracy = run_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        device,\n",
        "        should_train=True,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        scheduler=scheduler,\n",
        "        verbose=True,\n",
        "        best_model_path='best_model.pth',  # Specify the path to save the best model\n",
        "        val_loader=val_loader  # Provide the validation loader\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set for one epoch\n",
        "    val_loss, val_accuracy, _ = run_epoch(\n",
        "        model,\n",
        "        val_loader,\n",
        "        device,\n",
        "        should_train=False,\n",
        "        optimizer=None,\n",
        "        criterion=criterion,\n",
        "        scheduler=None,\n",
        "        verbose=True,\n",
        "        best_model_path=None,  # Don't save the model here\n",
        "        val_loader=None  # No need for validation loader during eval\n",
        "    )\n",
        "\n",
        "    # Track losses and accuracies for each epoch\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}]: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you've trained your final model (or best model from k-folds)\n",
        "test_loss, test_accuracy = run_epoch(model, test_loader, device, should_train=False, optimizer=None, criterion=criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "CJgymBOxhyeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnZ0_FO3_gMM"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEGKfRkp_gUp"
      },
      "outputs": [],
      "source": [
        "# Plotting the training and validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting the training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(f'Final Validation Loss: {val_losses[-1]:.4f}, Final Validation Accuracy: {val_accuracies[-1]:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yjvzhaMMDsh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NPkSHwjJoi93",
        "4UeHOci7_BNC",
        "RcrbHISq_DAH",
        "zxFQ_ZeC_SI7",
        "dnZ0_FO3_gMM"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}